{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 275,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.18411967779056387,
      "grad_norm": 0.4716130793094635,
      "learning_rate": 0.00019672727272727273,
      "loss": 4.1626,
      "step": 10
    },
    {
      "epoch": 0.36823935558112775,
      "grad_norm": 0.7578698992729187,
      "learning_rate": 0.0001930909090909091,
      "loss": 4.0219,
      "step": 20
    },
    {
      "epoch": 0.5523590333716916,
      "grad_norm": 0.9403005242347717,
      "learning_rate": 0.00018945454545454547,
      "loss": 3.7484,
      "step": 30
    },
    {
      "epoch": 0.7364787111622555,
      "grad_norm": 1.1063607931137085,
      "learning_rate": 0.00018581818181818182,
      "loss": 3.4182,
      "step": 40
    },
    {
      "epoch": 0.9205983889528193,
      "grad_norm": 1.0262858867645264,
      "learning_rate": 0.00018218181818181818,
      "loss": 2.9765,
      "step": 50
    },
    {
      "epoch": 1.092059838895282,
      "grad_norm": 0.5893124938011169,
      "learning_rate": 0.00017854545454545456,
      "loss": 2.5487,
      "step": 60
    },
    {
      "epoch": 1.2761795166858458,
      "grad_norm": 0.45328429341316223,
      "learning_rate": 0.0001749090909090909,
      "loss": 2.4935,
      "step": 70
    },
    {
      "epoch": 1.4602991944764097,
      "grad_norm": 0.4169416129589081,
      "learning_rate": 0.00017127272727272727,
      "loss": 2.2775,
      "step": 80
    },
    {
      "epoch": 1.6444188722669737,
      "grad_norm": 0.4004078507423401,
      "learning_rate": 0.00016763636363636365,
      "loss": 2.2197,
      "step": 90
    },
    {
      "epoch": 1.8285385500575373,
      "grad_norm": 0.3426998257637024,
      "learning_rate": 0.000164,
      "loss": 2.2263,
      "step": 100
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.7169729471206665,
      "learning_rate": 0.00016036363636363636,
      "loss": 2.0686,
      "step": 110
    },
    {
      "epoch": 2.184119677790564,
      "grad_norm": 0.4183777868747711,
      "learning_rate": 0.00015672727272727274,
      "loss": 2.0739,
      "step": 120
    },
    {
      "epoch": 2.3682393555811276,
      "grad_norm": 0.3706539273262024,
      "learning_rate": 0.00015309090909090912,
      "loss": 2.0535,
      "step": 130
    },
    {
      "epoch": 2.5523590333716917,
      "grad_norm": 0.4479205012321472,
      "learning_rate": 0.00014945454545454547,
      "loss": 2.0084,
      "step": 140
    },
    {
      "epoch": 2.7364787111622553,
      "grad_norm": 0.4147777259349823,
      "learning_rate": 0.00014581818181818183,
      "loss": 2.0026,
      "step": 150
    },
    {
      "epoch": 2.9205983889528193,
      "grad_norm": 0.40345850586891174,
      "learning_rate": 0.00014218181818181818,
      "loss": 1.9726,
      "step": 160
    },
    {
      "epoch": 3.092059838895282,
      "grad_norm": 0.5332300662994385,
      "learning_rate": 0.00013854545454545456,
      "loss": 1.9729,
      "step": 170
    },
    {
      "epoch": 3.2761795166858456,
      "grad_norm": 0.5243620872497559,
      "learning_rate": 0.00013490909090909092,
      "loss": 1.9912,
      "step": 180
    },
    {
      "epoch": 3.4602991944764097,
      "grad_norm": 0.4804743826389313,
      "learning_rate": 0.00013127272727272727,
      "loss": 1.9554,
      "step": 190
    },
    {
      "epoch": 3.6444188722669737,
      "grad_norm": 0.4268469214439392,
      "learning_rate": 0.00012763636363636365,
      "loss": 1.8857,
      "step": 200
    },
    {
      "epoch": 3.8285385500575373,
      "grad_norm": 0.4612964987754822,
      "learning_rate": 0.000124,
      "loss": 1.9316,
      "step": 210
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.9542655348777771,
      "learning_rate": 0.00012036363636363637,
      "loss": 1.9006,
      "step": 220
    },
    {
      "epoch": 4.184119677790564,
      "grad_norm": 0.6069860458374023,
      "learning_rate": 0.00011672727272727273,
      "loss": 1.8902,
      "step": 230
    },
    {
      "epoch": 4.368239355581128,
      "grad_norm": 0.4606870412826538,
      "learning_rate": 0.0001130909090909091,
      "loss": 1.9078,
      "step": 240
    },
    {
      "epoch": 4.552359033371691,
      "grad_norm": 0.5495200157165527,
      "learning_rate": 0.00010945454545454545,
      "loss": 1.8936,
      "step": 250
    },
    {
      "epoch": 4.736478711162255,
      "grad_norm": 0.5817802548408508,
      "learning_rate": 0.00010581818181818182,
      "loss": 1.9212,
      "step": 260
    },
    {
      "epoch": 4.920598388952819,
      "grad_norm": 0.589764416217804,
      "learning_rate": 0.00010218181818181818,
      "loss": 1.8438,
      "step": 270
    }
  ],
  "logging_steps": 10,
  "max_steps": 550,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 569625158615040.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
